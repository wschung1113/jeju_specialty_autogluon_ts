{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import pre_all\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"파이썬 버전 : {sys.version}\")\n",
    "print(f\"pandas 버전 : {pd.__version__}\")\n",
    "print(f\"numpy 버전 : {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. vanilla autogluon-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/train.csv')[['ID','timestamp','supply(kg)', 'price(원/kg)']]\n",
    "test_df = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/test.csv')[['ID','timestamp']]\n",
    "# train_df = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/train.csv')\n",
    "# test_df = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['item_id'] = train_df.ID.str[0:6]\n",
    "test_df['item_id'] = test_df.ID.str[0:6]\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TimeSeriesDataFrame(train_df.drop(columns=['ID']))\n",
    "predictor = TimeSeriesPredictor( \n",
    "    prediction_length=28,\n",
    "    target=\"price(원/kg)\",\n",
    "    eval_metric=\"RMSE\",\n",
    ")\n",
    "\n",
    "# seed 고정\n",
    "predictor.fit(data, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "pred = predictor.predict(data, random_seed=42)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['answer'] = pred.reset_index()['mean']\n",
    "submission.loc[ submission['answer'] < 0.0, 'answer'] = 0.0\n",
    "submission.to_csv('./dacon_submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. + static features + covariates + custom validation set + custom predictor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/train.csv')\n",
    "test_df = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['item_id'] = train_df.ID.str[0:6]\n",
    "test_df['item_id'] = test_df.ID.str[0:6]\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariates 생성\n",
    "train, test = pre_all(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make static_features_df\n",
    "static_features_df = train.loc[:, ['item_id', 'item', 'corporation', 'location']]\n",
    "static_features_df = static_features_df.drop_duplicates()\n",
    "print(static_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 별개의 static_features_df를 생성했으므로 학습 데이터에서는 drop\n",
    "train.drop(columns=['ID', 'item', 'corporation', 'location'], inplace=True)\n",
    "test.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    train,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    static_features_df=static_features_df,\n",
    ")\n",
    "\n",
    "print(train_data.head())\n",
    "print(train_data.static_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create own validation set (march 4~31 of 2019, 2020, 2021, 2022)\n",
    "march_2019_threshold = pd.to_datetime('2019-03-31')\n",
    "val_set_1 = train_data[train_data.index.get_level_values('timestamp') <= march_2019_threshold]\n",
    "\n",
    "march_2020_threshold = pd.to_datetime('2020-03-31')\n",
    "val_set_2 = train_data[(train_data.index.get_level_values('timestamp') > march_2019_threshold) & (train_data.index.get_level_values('timestamp') <= march_2020_threshold)]\n",
    "\n",
    "march_2021_threshold = pd.to_datetime('2021-03-31')\n",
    "val_set_3 = train_data[(train_data.index.get_level_values('timestamp') > march_2020_threshold) & (train_data.index.get_level_values('timestamp') <= march_2021_threshold)]\n",
    "\n",
    "march_2022_threshold = pd.to_datetime('2022-03-31')\n",
    "val_set_4 = train_data[(train_data.index.get_level_values('timestamp') > march_2021_threshold) & (train_data.index.get_level_values('timestamp') <= march_2022_threshold)]\n",
    "\n",
    "my_validation_dataset = pd.concat([val_set_1, val_set_2, val_set_3, val_set_4], axis=0)\n",
    "my_validation_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 시점에도 알 수 있는 covariate들을 known_covariates로 지정 (날짜, 휴일과 각각의 파생변수 등)\n",
    "known_covariates = [\"year\", \"month\", \"day\", \"week_day\", \"year_month\", \"week\", \"week_num\", \"holiday\"]\n",
    "\n",
    "# configure target and known, past covariates in predictor\n",
    "predictor = TimeSeriesPredictor( \n",
    "    prediction_length=28,\n",
    "    target=\"price\",\n",
    "    known_covariates_names=known_covariates, # supply and x_prev_price columns will automatically interpreted as past covariates\n",
    "    eval_metric=\"RMSE\",\n",
    ")\n",
    "\n",
    "# 관심이 있는 DLInear 모델과 PatchTST 모델 그리고 baseline으로 DeepAR과 Theta 모델만을 학습\n",
    "# 특산품 가격은 달마다의 계절성이 있다고 판단되어 PatchTST 모델의 look-back window를 365일로 지정\n",
    "# Transformer encoder layer은 default 2에서 6으로 확장\n",
    "predictor.fit(train_data,\n",
    "              random_seed=42,\n",
    "              tuning_data=my_validation_dataset,\n",
    "              hyperparameters={\n",
    "                \"DLinear\": {},\n",
    "                \"PatchTST\": [\n",
    "                    {\"context_length\": 365}, # default 96 (look-back window length)\n",
    "                    {\"num_encoder_layers\": 6}, # default 2\n",
    "                ],\n",
    "                \"DeepAR\": {},\n",
    "                \"Theta\": [\n",
    "                    {\"decomposition_type\": \"additive\"},\n",
    "                    {\"seasonal_period\": 1},\n",
    "                ],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\n",
    "\n",
    "future_index = get_forecast_horizon_index_ts_dataframe(train_data, prediction_length=28)\n",
    "future_timestamps = future_index.get_level_values(\"timestamp\")\n",
    "known_covariates_pred_df = pd.DataFrame(index=future_index)\n",
    "for kc in known_covariates:\n",
    "    known_covariates_pred_df[kc] = test_data[kc]\n",
    "known_covariates_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_covariates를 사용하여 학습한 모델이 있을 시 predict 시에도 제공해야함\n",
    "pred = predictor.predict(train_data,\n",
    "                         known_covariates=known_covariates_pred_df,\n",
    "                         random_seed=42,\n",
    "                         )\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TimeSeriesDataFrame can also be loaded directly from a file\n",
    "# test_data = TimeSeriesDataFrame.from_path(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/m4_hourly_subset/test.csv\")\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "# item_id = \"H1\"\n",
    "# item_id = \"TG_A_J\"\n",
    "item_id = \"RD_F_J\"\n",
    "y_past = train_data.loc[item_id][\"price\"]\n",
    "y_pred = pred.loc[item_id]\n",
    "# y_test = test_data.loc[item_id][\"price(원/kg)\"][-48:]\n",
    "\n",
    "plt.plot(y_past[-200:], label=\"Past time series values\")\n",
    "plt.plot(y_pred[\"mean\"], label=\"Mean forecast\")\n",
    "# plt.plot(y_test, label=\"Future time series values\")\n",
    "\n",
    "plt.fill_between(\n",
    "    y_pred.index, y_pred[\"0.1\"], y_pred[\"0.9\"], color=\"red\", alpha=0.1, label=f\"10%-90% confidence interval\"\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/sample_submission.csv')\n",
    "submission['answer'] = pred.reset_index()['mean']\n",
    "submission.loc[ submission['answer'] < 0.0, 'answer'] = 0.0\n",
    "submission.to_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/dacon_submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
